\item \defpoints{15} [Maximum Likelihood Estimation (MLE)]

Consider real-valued variables $X$ and $Y$, in which $Y$ is generated conditional on $X$ according to
$$Y = aX + b + \epsilon, \ \text{where} \ \epsilon \sim \mathcal{N}(0, \sigma^2)$$
Here $\epsilon$ is an independent variable, called a noise term, which is drawn from a Gaussian distribution with mean 0, and variance $\sigma^2$. This is a single variable linear regression model, where $a$ is the only weight parameter and $b$ denotes the intercept. The conditional probability of $Y$ has a distribution $p(Y | X, a, b) \sim \mathcal{N}(aX+b, \sigma^2)$, so it can be written as:
$$p(Y|X, a,b) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{1}{2\sigma^2}(Y - aX -b)^2\right)$$

(a) Assume we have a training dataset of $n$ i.i.d. pairs $(x_i, y_i), i = 1, 2, \ldots, n$, and the likelihood function is defined by $\mathcal{L}(a,b) = \prod\limits_{i=1}^n p(y_i | x_i, a, b)$. Please write the Maximum Likelihood Estimation (MLE) problem for estimating $a$ and $b$. ~\defpoints{5}

(b) Estimate the optimal solution of $a$ and $b$ by solving the MLE problem in (a).~\defpoints{5}

(c) Based on the result in (b), argue that the learned linear model $f(X) = aX + b$, always passes through the point $(\bar{x},\bar{y})$, where $\bar{x} = \dfrac{1}{n}\sum\limits_{i=1}^{n}x_{i}$ and $\bar{y} = \dfrac{1}{n}\sum\limits_{i=1}^{n}y_{i}$ denote the sample means.~\defpoints{5}

\solution









\newpage