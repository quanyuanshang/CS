{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import mnist\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "def save():\n",
    "    os.makedirs('mnist/train', exist_ok=True)\n",
    "    os.makedirs('mnist/test', exist_ok=True)\n",
    "    for i in range(10):\n",
    "        os.makedirs('mnist/train/' + str(i), exist_ok=True)\n",
    "        os.makedirs('mnist/test/' + str(i), exist_ok=True)\n",
    "\n",
    "    for i, item in enumerate(train_loader):\n",
    "        img, label = item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        img_path = 'mnist/train/' + str(label) + '/' + str(i) + '.jpg'\n",
    "        img.save(img_path)\n",
    "\n",
    "\n",
    "    for i, item in enumerate(test_loader):\n",
    "        img, label = item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        img_path = 'mnist/test/' + str(label) + '/' + str(i) + '.jpg'\n",
    "        img.save(img_path)\n",
    "\n",
    "\n",
    "def show():\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for i, item in enumerate(itertools.islice(train_loader,2,12)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        img,label= item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data = mnist.MNIST('mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_data = mnist.MNIST('mnist', train=False, transform=transforms.ToTensor(), download=True)\n",
    "    train_loader = data.DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_data, batch_size=1, shuffle=True)\n",
    "    train_total = train_loader.__len__()\n",
    "    test_total = test_loader.__len__()\n",
    "    labels = train_data.targets\n",
    "    dataiter = iter(train_data)\n",
    "    images, labs = dataiter.__next__()\n",
    "    save()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes=10, n1=16, n2=32, n3=64):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "    # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MnistDataSet(Dataset):\n",
    "    def __init__(self, data_dir, class_num=10, transform=None):\n",
    "        pass\n",
    "        # TODO\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # show some elements in dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "    dataset = MnistDataSet('mnist/test')\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "    img, label = dataset[0]\n",
    "    plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Batch {batch_idx+1}/{len(dataloader)} - Loss: {running_loss/(batch_idx+1):.4f}  Acc: {100.*correct/total:.2f}%')\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            # TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1} Summary: Train Loss {train_loss:.4f}, Train Acc {train_acc:.2f}%, Test Loss {test_loss:.4f}, Test Acc {test_acc:.2f}%')\n",
    "    print('-'*50)\n",
    "\n",
    "# Plot loss and accuracy curves\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, test_losses, label='Test Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save checkpoint\n",
    "# TODO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# TODO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss, test_acc = evaluate(model, dataloader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS182",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
