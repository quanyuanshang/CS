{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import mnist\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "\n",
    "def save():\n",
    "    os.makedirs('mnist/train', exist_ok=True)\n",
    "    os.makedirs('mnist/test', exist_ok=True)\n",
    "    for i in range(10):\n",
    "        os.makedirs('mnist/train/' + str(i), exist_ok=True)\n",
    "        os.makedirs('mnist/test/' + str(i), exist_ok=True)\n",
    "\n",
    "    for i, item in enumerate(train_loader):\n",
    "        img, label = item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        img_path = 'mnist/train/' + str(label) + '/' + str(i) + '.jpg'\n",
    "        img.save(img_path)\n",
    "\n",
    "\n",
    "    for i, item in enumerate(test_loader):\n",
    "        img, label = item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        img_path = 'mnist/test/' + str(label) + '/' + str(i) + '.jpg'\n",
    "        img.save(img_path)\n",
    "\n",
    "\n",
    "def show():\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for i, item in enumerate(itertools.islice(train_loader,2,12)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        img,label= item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_data = mnist.MNIST('mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_data = mnist.MNIST('mnist', train=False, transform=transforms.ToTensor(), download=True)\n",
    "    train_loader = data.DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "    test_loader = data.DataLoader(dataset=test_data, batch_size=1, shuffle=True)\n",
    "    train_total = train_loader.__len__()\n",
    "    test_total = test_loader.__len__()\n",
    "    labels = train_data.targets\n",
    "    dataiter = iter(train_data)\n",
    "    images, labs = dataiter.__next__()\n",
    "    save()\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, classes=10, n1=16, n2=32, n3=64):\n",
    "        super(CNN, self).__init__()\n",
    "        self.classes = classes\n",
    "        self.n1 = n1\n",
    "        self.n2 = n2\n",
    "        self.n3 = n3\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=self.n1, kernel_size=5, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=self.n1, out_channels=self.n2, kernel_size=5, stride=1, padding=0)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        # The linear layer input size (n2 * 4 * 4) is based on the output size of conv layers.\n",
    "        self.fc1 = nn.Linear(self.n2 * 4 * 4, self.n3)\n",
    "        self.fc2 = nn.Linear(self.n3, self.classes)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "            self.maxpool,\n",
    "            self.conv2,\n",
    "            nn.ReLU(),\n",
    "            self.maxpool,\n",
    "            nn.Flatten(),\n",
    "            self.fc1,\n",
    "            nn.ReLU(),\n",
    "            self.fc2,\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.conv1(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = self.maxpool(x)\n",
    "        # x = self.conv2(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = self.maxpool(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.fc1(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x = self.fc2(x)\n",
    "        # x = nn.Softmax()(x)\n",
    "\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cnn = CNN(classes=10)\n",
    "    print(cnn)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    cnn = cnn.to(device)\n",
    "    summary(cnn, (1, 28, 28), device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MnistDataSet(Dataset):\n",
    "    def __init__(self, data_dir, class_num=10, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Directory containing data, e.g., 'mnist/train' or 'mnist/test'\n",
    "            class_num (int): Number of classes (default is 10)\n",
    "            transform (callable, optional): Transform to be applied on a sample image\n",
    "        \"\"\"\n",
    "        super(MnistDataSet, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.class_num = class_num\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = []\n",
    "        # Loop through each class directory\n",
    "        for label in range(self.class_num):\n",
    "            label_dir = os.path.join(self.data_dir, str(label))\n",
    "            img_names = os.listdir(label_dir)\n",
    "            for img_name in img_names:\n",
    "                img_path = os.path.join(label_dir, img_name)\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.data[index]\n",
    "        # Open image and convert to grayscale to ensure one channel\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img, dtype=np.float32).reshape(1, 28, 28) / 255.0\n",
    "        return img, label\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # show some elements in dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "    dataset = MnistDataSet('mnist/test')\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "    img, label = dataset[0]\n",
    "    plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        # Move input data and labels to the specified device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Batch {batch_idx+1}/{len(dataloader)} - Loss: {running_loss/(batch_idx+1):.4f}  Acc: {100.*correct/total:.2f}%')\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_dataset = MnistDataSet(data_dir='mnist/train')\n",
    "test_dataset = MnistDataSet(data_dir='mnist/test')\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# num worker: cpu cores\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = CNN(classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1} Summary: Train Loss {train_loss:.4f}, Train Acc {train_acc:.2f}%, Test Loss {test_loss:.4f}, Test Acc {test_acc:.2f}%')\n",
    "    print('-'*50)\n",
    "\n",
    "# Plot loss and accuracy curves\n",
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, test_losses, label='Test Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Train Accuracy')\n",
    "plt.plot(epochs, test_accuracies, label='Test Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# save checkpoint\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(classes=10)\n",
    "checkpoint = torch.load('mnist_cnn.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dataset = MnistDataSet('mnist/test')\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss, test_acc = evaluate(model, dataloader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS182",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
